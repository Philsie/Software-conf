"""
Methods to save & load robot recordings in various formats.

This module is to be used both by the recorder node and by shellscripts.
(it seemed like a sanity-preserving move to keep encoding & decoding
code in the same place)
"""
import logging
import os
from typing import Any, Dict, Generator, List, Optional, Tuple
import numpy as np
import tempfile
import json
import shutil

from zipfile import ZipFile, BadZipFile

from shared_ml.io.video_compression import iter_video, save_video, load_video
from shared_ml.io.video_compression import get_video_size


def save(
    out_dir: str,
    name: str,
    metadata: Dict[str, Any],
    data: Dict[str, np.ndarray],
    keys_to_compress: List[str] = ['vision1', 'vision2'],
    logger: Optional[logging.Logger] = None,
) -> str:
    """
    Save episode with video compression

    The file is written to '<out_dir>/<name>.EXT', where EXT
    is taken from `metadata["episode_type"]`, defaulting to
    ".episode"

    It is a zip file containing:
    - an '.mp4' file for each camera stream
    - a .npy file for each of the other data arrays
    - a metadata.json

    Parameters:
    -----------
    out_dir : str
        The path to the folder in which the episode file will be saved.
        If this folder doesn't exist, it will be created.
    name : str
        The name of the episode file, excluding the '.episode' suffix.
    metadata : dict
        A dict of named bits of arbitrary metadata.
    data : dict of np arrays
        A dict of equally long columns of numerical data.
    keys_to_compress: list of str
        A list of column names to apply video compression to in case
        they are found in the `data` dict.
    logger : logger instance
        A hole to shout into.
    
    Returns:
    --------
    out_path : str
         The complete path to the file, as it came to look. If the
         `out_dir` is relative, the `out_path` will be, too.
    """

    lengths = [len(value) for value in data.values()]
    if lengths and len(set(lengths)) != 1:
        raise ValueError("Unequal episode column lengths: %s" %
                         {k: v.shape for k, v in data.items()})

    os.makedirs(out_dir, exist_ok=True)
    extension = metadata.get("episode_type", "episode")
    out_path = os.path.join(out_dir, name + f".{extension}")

    # assemble everything off-stage, so we never
    # (even temporarily) pollute the output directory:
    with tempfile.TemporaryDirectory() as tmp_dir:
        staging_dir = os.path.join(tmp_dir, 'stage')
        os.makedirs(staging_dir)

        fileinfo_path = os.path.join(staging_dir, 'version.txt')
        with open(fileinfo_path, 'w') as fi:
            fi.write("0")

        # We need to pick a framerate for the video compression. If
        # we happen to know the true recording frequency, we use that;
        # otherwise we fall back on a default of 15 frames per second.
        fps = metadata.get('runtime_steps_per_second', None)
        if fps is None:
            fps = 15
            if logger:
                logger.warning("No frequency info in metadata,"
                               " saving video with %s fps." % fps)

        for key, arr in data.items():
            if key in keys_to_compress:
                column_out_path = os.path.join(staging_dir, key + '.mp4')
                save_video(arr, column_out_path, crf=8, fps=fps)
            else:
                column_out_path = os.path.join(staging_dir, key + '.npy')
                np.save(column_out_path, arr)

        with open(os.path.join(staging_dir, 'metadata.json'), 'w') as mf:
            json.dump(metadata, mf)

        zip_path = os.path.join(tmp_dir, 'zipped')
        shutil.make_archive(zip_path, 'zip', root_dir=staging_dir)
        shutil.move(zip_path + '.zip', out_path)
        if logger:
            logger.info('Saved episode to %s' % out_path)
    
    return out_path


def load(
    filepath: str, logger: Optional[logging.Logger] = None, skip_fields: List[str] = []
) -> Tuple[Dict[str, np.ndarray], Dict[str, Any]]:
    """Load a .episode or .telemetry file.

    Parameters:
    -----------
    filepath : str
        Path to a zip-y file containing the data and metadata.
    logger : Logger
        A reporting device to talk into.
    skip_fields : list of strings
        A blacklist of exact column names (e.g., 'vision1') which
        should not be loaded if they are found in the episode.

    Returns:
    --------
    data : dict of np arrays
        A collection of named, equally long arrays.
    meta : dict
        A dict of arbitrary episode metadata.
    """

    episode_data = {}
    if logger:
        logger.debug('Loading episode %s' % filepath)

    # first extract everything, because ffmpeg will
    # need to access the mp4 files by path
    with tempfile.TemporaryDirectory() as tmp_dir:
        with ZipFile(filepath) as episode:
            full_names = [f.filename for f in episode.filelist]
            for full_name in full_names:
                first_name, last_name = full_name.split(".")
                if first_name not in skip_fields:
                    episode.extract(full_name, tmp_dir)

        versionfile = os.path.join(tmp_dir, "version.txt")

        with open(versionfile) as vf:
            version = vf.read()
            assert version == "0"

        for fname in os.listdir(tmp_dir):
            name, suffix = fname.split('.')
            fullpath = os.path.join(tmp_dir, fname)
            if suffix == 'npy':
                if name not in skip_fields:
                    episode_data[name] = np.load(fullpath)
            elif suffix == 'mp4':
                if name not in skip_fields:
                    episode_data[name] = load_video(fullpath)
            elif suffix == 'json':
                with open(fullpath, 'r') as mf:
                    metadata = json.load(mf)
            elif fname == "version.txt":
                pass  # do something with the version file?
            else:
                raise ValueError('Unknown file extension: %s in episode %s' %
                                 (fname, filepath))

    lengths = [value.shape[0] for value in episode_data.values()]
    if lengths and len(set(lengths)) != 1:
        raise ValueError("Unequal episode column lengths: %s" %
                         {k: v.shape for k, v in episode_data.items()})

    return episode_data, metadata


# support some legacy names (dating back to when compression was optional)
load_compressed = load
save_compressed = save


def load_metadata(
    filepath: str, logger: Optional[logging.Logger] = None
) -> Dict[str, Any]:
    """Load the meta-data from an episode file.

    Parameters:
    -----------
    filepath : str
        Path to an episode file containing the data and metadata.
    logger : Logger
        A reporting device to talk into.

    Returns:
    --------
    meta : dict
        A dict of arbitrary episode metadata.

    Raises:
    -------
    FileNotFoundError :
        If the file path does not point to anything.
    BadZipFile :
        If a path to an `.episode` file is given, but the file cannot
        be interpreted as a valid zip file.
    KeyError :
        If the file exists and is a valid zip archive, but no metadata
        has been found in the folder.
    """

    if logger:
        logger.debug('Loading metadata from episode %s' % filepath)

    with ZipFile(filepath) as episode:
        with tempfile.TemporaryDirectory() as tmp_dir:
            jsonpath = episode.extract("metadata.json", path=tmp_dir)
            with open(jsonpath) as source:
                return json.load(source)


def extract_field(
    filepath: str, key: str, logger: Optional[logging.Logger] = None
) -> np.ndarray:
    """Load a specific, named data column out of an episode file.

    Parameters:
    -----------
    filepath : str
        Path to an episode file containing the data and metadata
    key : str
        The name of a data column (field) to extract.
    logger : Logger
        A reporting device to talk into.

    Returns:
    --------
    column : np.ndarray
        The data column of the given name from the indicated episode.

    Raises:
    -------
    FileNotFoundError :
        If the file path does not point to anything.
    BadZipFile :
        If a path to an `.episode` file is given, but the file cannot
        be interpreted as a valid zip file.
    KeyError :
        If the file exists and is a valid zip archive, but no the
        requested column is not found in the episode.
    """

    if logger:
        logger.debug('Loading metadata from episode %s' % filepath)

    with ZipFile(filepath) as episode:
        with tempfile.TemporaryDirectory() as tmp_dir:
            fullname = "%s.npy" % key
            archive = episode.extract(fullname, path=tmp_dir)
            return np.load(archive)


def iter_episode(
    filepath: str, logger: Optional[logging.Logger] = None
) -> Generator[Dict[str, np.ndarray], None, None]:
    """Iterate over the co-timed entries of an episode file.

    Parameters:
    -----------
    filepath : str
        Path to an episode file containing the data and metadata.
    logger : Logger
        A reporting device to talk into.

    Yields:
    -------
    observation : dict
        A collection of named single-time-step observations.

    Raises:
    -------
    FileNotFoundError :
        If the file path does not point to anything.
    ValueError :
        If the file is of an unknown file type (i.e., last name).
    BadZipFile :
        If a path to an `.episode` file is given, but the file cannot
        be interpreted as a valid zip file.
    """

    if logger:
        logger.debug('Loading episode %s' % filepath)

    with tempfile.TemporaryDirectory() as tmp_dir:

        with ZipFile(filepath) as episode:
            episode.extractall(tmp_dir)

        versionfile = os.path.join(tmp_dir, "version.txt")
        if os.path.isfile(versionfile):
            with open(versionfile) as vf:
                version = vf.read()
                assert version == "0"

        col_names = []
        col_iterators = []
        lengthdict = {}

        for fname in os.listdir(tmp_dir):
            name, suffix = fname.split('.')
            fullpath = os.path.join(tmp_dir, fname)
            if name == "meta":
                pass
            elif suffix == "json":
                pass
            elif fname == "version.txt":
                pass
            elif suffix == 'npy':
                col_names.append(name)
                column_data = np.load(fullpath)
                col_iterators.append(column_data)
                lengthdict[name] = len(column_data)
            elif suffix == 'mp4':
                col_names.append(name)
                column_data = iter_video(fullpath)
                col_iterators.append(column_data)
                nframes, _, _ = get_video_size(fullpath)
                lengthdict[name] = nframes
            else:
                raise ValueError('Unknown file extension: %s in episode %s' %
                                 (fname, filepath))

        if lengthdict and len(set(lengthdict.values())) != 1:
            raise ValueError("Unequal column lengths in %r: %s" %
                             (filepath, lengthdict))

        for row in zip(*col_iterators):
            yield {name: cell for name, cell in zip(col_names, row)}



