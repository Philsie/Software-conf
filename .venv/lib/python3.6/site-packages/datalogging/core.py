import pickle
import threading
import logging
import socket
import io
import copy
import time
import importlib
from zlib import adler32
import signal
import numpy as np
import stackprinter
import sys


from datetime import datetime
from collections import defaultdict

from logging.handlers import DatagramHandler
from datalogging.helpers import start_listener, compress, decompress, TracebackThread

allowed = {'numpy': ['ndarray', 'dtype'],
           'numpy.core.multiarray': ['_reconstruct', 'scalar'],
           'numpy.core._multiarray_umath': ['_reconstruct', 'scalar'],
            # np 1.16.0 moved some stuff out of core.multiarray into this weird
            # hidden namespace there, so our Unpickler needs to be happy to
            # unpickle things from that weird module too. newer versions of
            # np should be fine again https://github.com/numpy/numpy/pull/11880
           'collections': ['OrderedDict'],
           '_codecs': ['encode'],
           'datetime': ['datetime']}

udp_maximum_packet = 50000

default_host = "127.0.0.1"
default_port = 61000
used_up_ports = defaultdict(lambda: [])


def show_loggers():
    """
    Get a dict describing the existing loggers and their status.

    The dict is JSON-packable (contains only bools, ints, strings) and
    looks like this, for example:

            {'some logger': {'active': True,
                             'seconds_since_last_log': 23,
                             'target_host': 'lab3',
                             'target_port': 12345},
             'another one': {'active': True,
                             'seconds_since_last_log': -1,  # <- never fired
                             'target_host': 'lab3',
                             'target_port': 12387}
             ...
             }
    """
    dataloggers = {}
    for name, lg in logging.root.manager.loggerDict.items():
        if isinstance(lg, DataEnabledLogger):
            host, port = lg.get_target_address()
            state = {"active": lg.is_active,
                     "seconds_since_last_log": lg.get_seconds_since_last_log(),
                     "target_host": host,
                     "target_port": port}
            dataloggers[name] = state
    return dataloggers


def deactivate_logger(name):
    """ Let this logger ignore & return immediately from all log calls """
    logger = logging.getLogger(name)
    logger.deactivate()


def activate_logger(name):
    """ Let this logger actually process log calls """
    logger = logging.getLogger(name)
    logger.activate()


def deactivate_all():
    """ Let all loggers ignore all log calls """
    for lg in logging.root.manager.loggerDict.values():
        if isinstance(lg, DataEnabledLogger):
            lg.deactivate()

def change_target(host, logger_name=None, port=None):
    """
    Change the target adress of one or all dataloggers

    Params
    ---
    host : str
        the target host, e.g. 'lab3' or '192.168.1.234'
    logger_name : str (optional)
        Which logger to change - leave empty to change all.
    port : int (optional)
        The UDP port on the target machine that this logger should send to.
        Leave empty to keep the existing port. Can only be set if a specific
        `logger_name` is given, since loggers need unique ports.
    """
    if logger_name:
        logger = logging.getLogger(logger_name)
        assert isinstance(logger, DataEnabledLogger), "%r is not a datalogger" % logger_name
        loggers = [logger]
    else:
        assert port is None, "Provide a specific logger name to change its port"
        loggers = [lg for lg in logging.root.manager.loggerDict.values()
                   if isinstance(lg, DataEnabledLogger)]

    for logger in loggers:
        logger.set_target_address(host, port)


class RestrictedUnpickler(pickle.Unpickler):
    def find_class(self, module, name):
        if module in allowed.keys():
            if name in allowed[module]:
                mod = importlib.import_module(module)
                return getattr(mod, name)
        raise pickle.UnpicklingError("Pickling %s.%s is not allowed" %
                                     (module, name))


def restricted_loads(s):
    return RestrictedUnpickler(io.BytesIO(s)).load()


class DataEnabledUDPHandler(DatagramHandler):
    def __init__(self, host, port, limiter=1e-3):
        """
        logger handler taking care of sending logged data via UPD.

        Params
            host: str
            port: int
            limiter (optional): Nr of seconds to sleep between sent data packets

        """
        super().__init__(host, port)
        self.host = host
        self.port = port
        self.max_pkt = udp_maximum_packet
        self.interrupted = False
        self.limiter = limiter
        self.cond = threading.Condition()
        self.sender = TracebackThread(target=self._send_loop, daemon=True,
                                       name="DataLogger_%s:%s" % (self.host, self.port))
        self.sender.start()

    def emit(self, record):
        self.rec = {'msg': record.msg, 'data': record.data, 'step': record.step,
                    'timestamp': record.timestamp,
                    'image_quality': record.image_quality}

        with self.cond:
            self.cond.notify()

    def shutdown(self):
        self.interrupted = True  # stop the loop
        with self.cond:
            self.cond.notify()
        self.sender.join()
        super().close()  # close the socket

    def _send_loop(self):
        while not self.interrupted:
            with self.cond:
                self.cond.wait()
            # tic = time.perf_counter()
            rec = getattr(self, 'rec', None)
            if rec is not None:
                rec = compress(rec)
                s = pickle.dumps(self.rec)
                s += adler32(s).to_bytes(4, 'big')
                if len(s) < self.max_pkt:
                    super().send(s)
                    time.sleep(self.limiter)
                else:
                    pack_num = int(len(s) / self.max_pkt)
                    if (len(s) % self.max_pkt):
                        pack_num += 1
                    mp = pickle.dumps({'msg': 'multipacket',
                                       'total_packets': pack_num,
                                       'packet_size': self.max_pkt})
                    mp += adler32(mp).to_bytes(4, 'big')
                    super().send(mp)
                    try:
                        for i in range(pack_num):
                            if i == pack_num - 1:
                                super().send(s[i*self.max_pkt:])
                            else:
                                super().send(s[i*self.max_pkt:(i+1)*self.max_pkt])
                            time.sleep(self.limiter)
                    except OSError as err:
                        import errno
                        if err.args[0] == errno.EMSGSIZE:
                            logging.getLogger("system").error("""
                                *** ERROR ***
                                Your system's max UDP size setting is too low.
                                If you're on MAC OS X please run:
                                    sudo sysctl -w net.inet.udp.maxdgram=65535
                                """)
                            return
            # print("sending took %.2fms" % ((time.perf_counter() - tic) * 1000))

class DataEnabledLogger(logging.Logger):
    def __init__(self, name, level="DEBUG"):
        """ Logger that accepts non-string data """
        self.deactivate()
        self.last_log_event = None
        self.reconfiguration_lock = threading.RLock()
        logging.Logger.__init__(self, name, level)

    def info(self, *args, **kwargs):
        self.log('INFO', *args, **kwargs)

    def debug(self, *args, **kwargs):
        self.log('DEBUG', *args, **kwargs)

    def warning(self, *args, **kwargs):
        self.log('WARNING', *args, **kwargs)

    def error(self, *args, **kwargs):
        self.log('ERROR', *args, **kwargs)

    def log(self, level, data=None, msg=None, step=None, timestamp=None,
            image_quality=None):
        """ Log the given message & data

        Params
            level: log level
                can be given as integer (e.g. logging.DEBUG) or
                as the corresponding string (e.g. 'DEBUG').

            data:
                any python built-in data type or numpy array
                or combination thereof.

            msg: string
                optionally add a log message - this is a logger after all

            step: int
                optionally give a consecutive numbering to your
                log events, so listeners can check if they
                received all of them.

            timestamp:
                optional timestamp of any type, defaults to a
                `datetime` of the current system time.

            image_quality: None or int from 1 to 95
                If given, compress image content with the given jpeg
                quality. Jpeg compression is applied if `data` is an
                image array, or a dict some of whose values are image
                arrays. An image array is a WxH or WxHx3 uint8 array.

        """
        if not self.is_active:
            return

        if msg is None:
            msg = self.name

        assert isinstance(msg, str)

        now = datetime.now()
        self.last_log_event = now

        if timestamp is None:
            timestamp = now

        level = logging._checkLevel(level)

        with self.reconfiguration_lock:
            super().log(level, msg, extra={"data": copy.deepcopy(data),
                                           "timestamp": timestamp,
                                           "step": step,
                                           "image_quality": image_quality})

    def activate(self):
        self.is_active = True

    def deactivate(self):
        self.is_active = False

    def is_configured(self):
        """ Tell whether this logger is ready to send (== has a UDP handler) """
        return self._get_data_handler() is not None

    def get_target_address(self):
        """
        Get this logger's (UDP handler's) target host and port.

        Returns
        ---
        host : string
            may be "None" if the logger isn't fully configured
        post : int
            may be -1 if the logger isn't fully configured
        """
        with self.reconfiguration_lock:
            handler = self._get_data_handler()
        if handler is None:
            return ("NONE", -1)
        else:
            return (handler.host, handler.port)

    def set_target_address(self, new_host, new_port=None, limiter=None):
        """
        Give this logger a new UDP handler with a new target host & port

        Params
        --
        new_host: string
            adress the logged data will be sent to

        new_port: int
            The UDP port on the given host where logged data will be sent to.
            If not given, keeps the existing port.

        limiter (optional): float
            Nr of seconds to sleep between sending data packets. If the logger
            takes too much CPU time or if the receiver cannot keep up, a higher
            wait time may help (at the cost of more dropped log events).
            If not given, keep the previously configured limiter.
        """
        with self.reconfiguration_lock:
            handler = self._get_data_handler()
            if handler is None:
                assert not (None in [new_host, new_port, limiter])
            else:
                old_host = handler.host
                old_port = handler.port
                old_limiter = handler.limiter
                handler.shutdown()
                self.removeHandler(handler)
                try:
                    used_up_ports[old_host].remove(old_port)
                except (KeyError, ValueError):
                    pass
                limiter = old_limiter if limiter is None else limiter
                new_port = old_port if new_port is None else new_port
            hdl = DataEnabledUDPHandler(new_host, new_port, limiter)
            self.addHandler(hdl)
            used_up_ports[new_host].append(new_port)

    def _get_data_handler(self):
        """
        Return the one UDP handler instance of this logger, if configured

        Returns:
        ----
        DataEnabledUDPHandler instance or None

        Raises:
        ----
        RuntimeError if the logger has no or multiple handlers
        """
        is_datahandler = lambda hd: type(hd).__name__ == DataEnabledUDPHandler.__name__
        handlers = [hd for hd in self.handlers if is_datahandler(hd)]
        n_handlers = len(handlers)
        if n_handlers == 0:
            return None
        elif n_handlers > 1:
            raise RuntimeError("Found %s handlers instead of one" % n_handlers)
        else:
            return handlers[0]

    def get_seconds_since_last_log(self):
        """ Get a string describing when this logger last fired """
        if self.last_log_event is None:
            return -1
        else:
            return (datetime.now() - self.last_log_event).seconds


def getLogger(loggername, host=default_host, port=None, limiter=1e-3,
              with_listener='', listener_args=[], activate=True):
    """
    Get a data logger

    Provides a datalogger that can send data via UDP to the given adress & port.

    Params
        host: string.
            adress the logged data will be sent to

        port: int.
            The UDP port on the given host where logged data will be sent to.
            If not given, defaults to some port >= 61000

        limiter (optional): Nr of seconds to sleep between sending data packets.
        If the logger takes too much CPU time or if the receiver cannot keep up,
        a higher wait time may help (at the cost of more dropped log events).

        with_listener: str
            Starts a subprocess with `python -m $with_listener port`
            and attaches the resulting process object to our logger instance as
            `logger.listener_process`. The subprocess is stopped on interpreter
            exit.

        listener_args: list of str
            additional command line arguments to pass to listener process

        active: bool
            Set to False to get a logger that ignores all log calls until you
            personally activate it with `datalogging.activate_logger('loggername')`,
            for example from an interactive console.
            Dataloggers can be activated/deactivated (in addition to respecting log levels)
            so you're free to sprinkle lots of them through your code without worrying
            too much about the performance impact. While the `log()` call itself always
            returns immediately even on an activated logger, each log event causes some
            background activity to pack and send your data. Since this is python, it's
            a bit of an empirical question how much that affects the performance of
            other running threads, depending on the data size and log frequency etc.


    Returns
        DataEnabledLogger instance, which holds a DataEnabledUDPHandler
        that points to the given adress & port

    """
    syslogger = logging.getLogger('system')

    # To tell the logging module to create a DataEnabledLogger we briefly switch
    # the default logger class. (I don't know another way to create a custom
    # logger so that it's registered in the logging machinery).
    # Other code will still want to create normal loggers, so we only switch it
    # temporarily, and prevent other threads from getting new loggers / changing
    # logging configs by hogging the module-level RLock during that time.
    logging._acquireLock()
    default_loggerclass = logging.getLoggerClass()
    logging.setLoggerClass(DataEnabledLogger)
    logger = logging.getLogger(loggername)
    logging.setLoggerClass(default_loggerclass)
    logging._releaseLock()

    # activate the logger if requested, but _don't_ deactivate otherwise.
    if activate:
        logger.activate()

    # Find out if this logger has previously been set up:
    if logger.is_configured():
        return logger

    # Nope, seems to be a fresh logger, so it needs some more setup
    if port is None:
        port = default_port
        while port in used_up_ports[host]:
            port += 1

    logger.propagate = False
    logger.set_target_address(host, port, limiter)

    syslogger.info("Datalogger %s will log to %s:%s" % (logger.name, host, port))

    if with_listener:
        assert not hasattr(logger, 'listener_process')  # Should be impossible
        listener_process = start_listener(with_listener, port, listener_args)
        logger.listener_process = listener_process

    return logger


class DataLogListener:
    def __init__(self, port, host='0.0.0.0', handler=None):
        """ Read log data at the given host & port and pass it to a handler method.

        The handler can either be given here as an argument or
        it can be implemented by subclassing DataLogListener.

        Params
        ----

        host: str
            Defaults to 0.0.0.0, "listen on all network interfaces"
        port: int

        handler: callable (optional)
            will be called with a dict {'msg':str, 'step':int, 'data':[*]}

        """

        self.host = host
        self.port = port
        self._handler = handler
        self.max_pkt = udp_maximum_packet
        self.data = dict()
        self.interrupted = False

        def timeout_handler(sig, frame):
            raise TimeoutError()

        if sys.platform != "win32":
            signal.signal(signal.SIGALRM, timeout_handler)

    def handler(self, rec):
        """ Call the handler function that was given to init

        Or override this method in a subclass
        """
        self._handler(rec)

    def run(self, timeout=0):
        """ Start listening for datalogging packets

        A timeout can be set to avoid excessive blocking. This can be handy
        when the listener runs in the main thread (which it should if the data
        handler expects to control a GUI event loop).

        Params
            timeout: int. If > 0, a TimeoutException is raised
            when we receive no packets in that number of seconds.

        Raises
            TimeoutException

        """

        with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as sock:
            sock.bind((self.host, self.port))
            mp_left = 0
            pkt = bytearray()
            print("Listening for packets on %s:%s" % (self.host, self.port))
            while not self.interrupted:
                signal.alarm(timeout)
                data, addr = sock.recvfrom(self.max_pkt)
                signal.alarm(0)

                try:
                    crc = int.from_bytes(data[-4:], 'big')
                    assert adler32(data[:-4]) == crc
                    obj = restricted_loads(data[:-4])
                    assert 'msg' in obj.keys()
                except:
                    # TODO stop doing control flow with exceptions..
                    pass
                else:
                    if obj['msg'] == 'multipacket':
                        mp_left = obj['total_packets']
                        pkt = bytearray()
                    else:
                        self.handler(decompress(obj))
                    continue

                if mp_left > 0:
                    pkt += data
                    mp_left -= 1
                    if mp_left == 0:
                        try:
                            crc = int.from_bytes(pkt[-4:], 'big')
                            assert adler32(pkt[:-4]) == crc
                            obj = restricted_loads(pkt[:-4])
                        except:
                            print(stackprinter.format(),
                                  "\n Error while reading multi-packet")
                        else:
                            self.handler(decompress(obj))

        print('Listener stopped.')

    def interrupt(self):
        """ Try to stop the listener """
        self.interrupted = True
